---
title: "三代测序"
author: "Shawn Wang"
date: Sep 30,2022
format: html
editor: visual
bibliography: PosDocProject.bib
---

<center>

<font color=salmon size=2pt> 🏡Zhang Lab, Aug 05, 2022 🏡</font>

<font color=green size=2pt> 🔬Multi-omics research center, State Key Laboratory of Crop Stress Adaption and Improvement, HENU, Kaifeng, Henan 🔬</font>

</center>

```{r,message=FALSE, warning=FALSE, include=FALSE, out.width='100%'}
suppressMessages(library(bruceR))
suppressMessages(library(tidyverse))
```


# 2.1 三代全长转录组测序方法

## 2.1.1 样品检测

  PacBio Iso_seq RNA样品检测方法包括以下两种：

  1. NanoDrop 2000分光光度法：检测Total RNA的浓度和纯度(OD 260/280 比值)；

  2. Agilent 2100系统：检测Total RNA完整度和浓度定量。   

## 2.1.2 文库制备

  样品要求浓度和总量达标，RNA完整无降解,无DNA和蛋白污染，无高浓度离子、螯合剂、变性剂等杂质，即可进入建库流程.文库构建流程如下：

  1. 用带有Oligo(dT)的磁珠富集真核生物mRNA；

  2. 使用SMARTer™ PCR cDNA Synthesis Kit，将mRNA反转录成cDNA；

  3. PCR扩增富集全长cDNA；

  4. 使用BluePippin筛选全长cDNA片段，构建不同长度插入片段的文库；

  5. 筛选后的全长cDNA进行再次PCR富集；

  6. 对全长cDNA进行末端修复，连接SMRT哑铃型接头，获得SMRT bell文库；

  7. 使用BluePippin针对3-6kb和5-10kb SMRT bell文库(可选)进行二次筛选，获得测序文库。   

## 2.1.3 库检及上机测序

  不同长度的文库构建完成后，先使用Qubit 2.0进行定量，并用Agilent 2100对文库的insert size进行检测，经PacBio Caculater计算后，按照比例将测序引物和测序酶结合到SMRT模板上，进行上机测序。

  PacBio RSII系列和Sequel测序系统以SMRT Cell为测序载体，分别含有150,000个和1,000,000纳米级的零模波导孔(ZMW)，每个ZMW能包含一个DNA聚合酶及一条DNA样品链，并通过不同荧光标记的核苷酸及荧光激发的过程，将不同碱基的信号捕捉下来，从而得到碱基序列信息。

  PacBio测序系统测序平均读长8Kb-15Kb，最长可达到40Kb-80Kb。目前PacBio RSII测序仪可以产出数据500Mb-1.5Gb/SMRT Cell，而新型Sequel则可以产出2Gb-5Gb/SMRT Cell。对于单个样本检测中高表达转录本，一般需要4Gb的数据产出；对于混合样本检测中高表达转录本，一般需要8Gb的数据产出。

# 2.2 信息分析流程

## 2.2.1 插入序列质控：  
对于测序下机的数据，首先过滤掉接头和低质量序列，得到Subreads。筛选满足number of full passes>=1，序列准确性大于0.9的Subreads得到一致性序列，即是每个ZMW小孔的插入序列(Reads of Insert,简称ROI)。   

## 2.2.2 转录本的分类：  
对于上一步获得的ROI，按照是否含有3´引物和5´引物，及3´引物前是否含有polyA尾将ROI分为全长转录本和非全长转录本；按照序列内部有无测序引物将ROI分为嵌合转录本和非嵌合转录本；对ROI分类后，取全长非嵌合的转录本进行聚类，去掉一部分冗余的转录本；为了提高序列的准确性，聚类后的全长非嵌合转录本可以用非全长的转录本进行序列矫正。  

## 2.2.3 转录本的聚类和矫正：   

获得全长转录本后，由于全长转录本中可能存在很多重复的转录本，我们需要对转录本进行聚类。通过ICE(isoform-level clustering algorithm)算法对全长转录本序列进行迭代聚类，将相似的序列聚类到一簇cluster，每个cluster得到一个一致转录本。  
结合非全长序列，使用矫正(polish)程序对各cluster中的一致序列进行校正。得到准确度大于99%的高质量转录本(HQ,high-quality isoforms)和低质量转录本(LQ,low-quality)转录本。   

## 2.2.4 全长转录本去冗余： 
由于全长转录本在聚类过程中参数设置较严格，为得到质量较高的一致转录本序列，同一转录本的多拷贝序列分到不同cluster的可能性较大，会产生一些冗余的序列。同时，全长转录本测序过程中，由于3’端存在poly-A结构，可以确定3’端比较完整，而5’端序列容易降解，导致同一转录本的不同拷贝分到不同的cluster中，如下图绿色圈中所示，5’端差异造成不同转录本，导致冗余序列的产生。此外，不同长度的cDNA文库之间也可能存在重复的序列，亦会产生冗余的序列。 对于无参全长转录组，我们采用CD-HIT软件对高质量全长转录本进一步去冗余(参数：c=0.99、T=6、G=1、U=10、s=0.999、d=40、p=1)，去冗余后得到非冗余的高质量转录本。

## 2.2.5 转录本注释：  
为了得到全长转录本的功能信息，我们将高质量的全长转录本序列分别与NT、NR、GO、KOG、KEGG、Swissprot等数据库进行比对，比对完根据E-value < 1E5进行筛选，选择得分最高的（top hit）annotation进行保留。

  Nt(NCBI nucleotide sequences)是NCBI官方的核酸序列数据库，包括了GenBank,EMBL和DDBJ（但不包括 EST,STS,GSS,WGS,TSA,PAT,HTG序列）的核酸序列。

  Nr(NCBI non-redundant protein sequences)是NCBI官方的蛋白序列数据库，它包括了GenBank 基因的蛋白编码序列，PDB(Protein Data Bank)蛋白数据库、SwissProt蛋白序列及来自PIR（Protein Information Resource）和PDF（Protein Research Foundation）等数据库的蛋白序列。

  Swiss-Prot(A manually annotated and reviewed protein sequence database)搜集了经过有经验的生物学家整理及研究的蛋白序列。详见 http://www.ebi.ac.uk/uniprot/。

  Gene Ontology（简称 GO）是一个国际标准化的基因功能分类体系，提供了一套动态更新的标准词（controlled vocabulary）来全面描述生物体中基因和基因产物的属性。

  KEGG是Kyoto Encyclopedia of Genes and Genomes的简称，是系统分析基因产物和化合物在细胞中的代谢途径以及这些基因产物的功能的数据库。KEGG是Kyoto Encyclopedia of Genes and Genomes的简称，是系统分析基因产物和化合物在细胞中的代谢途径以及这些基因产物的功能的数据库。它整合了基因组、化学分子和生化系统等方面的数据，包括代谢通路（KEGG PATHWAY）、药物（KEGG DRUG）、疾病（KEGG DISEASE）、功能模型（KEGG MODULE）、基因序列（KEGG GENES）及基因组（KEGG GENOME）等等。详见 http://www.genome.jp/kegg/。

  KOG和COG都是基于基因直系同源关系，其中COG针对原核生物，KOG针对真核生物。COG/KOG结合进化关系将来自不同物种的同源基因分为不同的Ortholog簇。来自同一ortholog的基因具有相同的功能，这样就可以将功能注释直接继承给同一COG/KOG簇的其他成员。详见http://www.ncbi.nlm.nih.gov/COG/。
  


## 2.2.6 CDS预测：

基于序列上的翻译阅读框，我们采用TransDecoder软件对去冗余后的高质量全长转录本进行CDS预测，预测后的CDS结果以fasta文件格式保存。  
  TransDecoder计算并比较6个翻译框的编码可能性值（coding likelihood score），找出能编码100个氨基酸以上的CDS；当翻译框的编码可能性值较低时，还可以根据同已知蛋白数据库（Pfam、 SwissProt）的同源搜索结果作为保留翻译框的依据。  
  


# 3.1 全长转录组测序

::: {#fig-batcheffect layout-nrow="2"}
![PicBio文库示意图](subreads.definition.png){#Def}

![嵌合序列示意图](chimeras.definition.png){#Def2}

PacBio文库构建
:::

## Terms:

| 全称                                    | 描述                                                                                                                                                                       |
|------------------------------------|------------------------------------|
| Single Molecule, Real-Time sequencing， （SMRT） bell                               | PacBio平台构建的文库形状是一个类似哑铃("套马环")的结构，称为SMRT bell文库，中间是测序片段，两端是环状的测序接头                                                            |
Zero-Mode Waveguides （ZMW） | ZMW（Zero-Mode Waveguides）孔，即零模波导孔。每一个SMRT Cell 中含有大量这种圆形纳米小孔，直径为50~100nm，该小孔利用了一种物理效应零模波导，外径比激发光波长小，当 DNA 分子进入小孔后，因激发光从孔底发出的光不能穿透小孔进入上方的溶液区，仅被限制在底部一个足以覆盖被检测 DNA 部分的区域，进而收集该区域的信号，将背景噪音降到最低。
| Polymerase read                         | 测序读段，指由DNA聚合酶沿着"套马环"模板链反应合成的核苷酸序列                                                                                                              |
| Subread                                 | 测序读段，根据接头序列将Polymerase read打断后的序列，去除5´和3测序引物后的序列                                                                                             |
| number of full passes                   | 指原始序列中存在两端均含有SMRT adapter的子序列个数                                                                                                                         |
| Reads of Insert （ROI）                 | 比对后的一致性序列，当ZMW小孔中的Polymerase read被打断成多个subreads时，它们的一致性序列即是每个ZMW小孔的Reads of Insert(ROI)                                              |
Circular Consensus Sequence CCS | 环装一致性序列，是一个 Polymerase read 上的多条 subreads 序列，相互校正得到的一条反映真实文库的序列。
| Full-Length Read 、Non-Full-Length Read | 全长转录本和非全长转录本，两端同时含有3´引物和5´引物，及3´引物前含有polyA尾的Reads of Insert称为全长转录本(Full-Length Read)。反之，则为非全长转录本(Non-Full-Length Read) |
| Chimeras                                | 零模波导孔中也会测到一些异常的插入读段，例如嵌合序列(Chimeras)。往往是由接头浓度不足、PCR引物浓度或生物学原因引起原始序列的插入读段间接头或引物缺失而形成的                |
High fidelity reads （HiFi reads）| 是 Sequel II 三代测序平台推出的兼顾长读长和高准确度的测序序列，HiFi reads 具有 >99.9% （Q20）单分子 reads 准确度的准确率。

## 3.1.1 Overview

本研究基于PacBio Sequel II 平台共产生了75.66Gb的全长转录组数据，经过去除接头序列，去除低质量序列后，我们检测到了38,696,058条Subreads，Subreads的N50达到2164bp，平均长度达到了1955bp，筛选满足number of full passes >= 1,序列准确性大于0.9的subreads得到一致性序列，最终得到4,714,912条高质量的ROI （Figure 4 A and B），这些ROI被称为High fidelity reads （HiFi reads）经过统计，HiFi reads的长度范围约为300-7000，均值为1997bp. 质控的结果显示，HiFi reads的错误检出路普遍较低，均值为Q41（Table S4 Figure 4 B)。我们对HiFi reads进行分类，全长非嵌合转录本（full-length non-chimeric reads）占88.28%,这些全长非嵌合转录本的平均长度为1,947bp, N50为2,196bp，获得全长转录本后我们经过聚类和矫正最终得到324,703个高质量的转录本及4273个低质量的转录本。随后我们通过CD-hit对全长转录本去冗余最终得到了176643个高质量的非冗余转录本。此外，我们通过BUSCO软件使用绿色植物保守单拷贝基因数据库对黄精块茎的全长转录组组装数据进行了评估，结果表明在数据库中的425个单拷贝基因在我们的数据中有355/356(去冗余/全部)个基因是完整的，占比为84%（Figure 4 C, TableS4,  TableS5），说明测序质量良好。



::: {#fig-batcheffect layout-nrow="1"}  

![Figure 4 Overview of full-length transcriptome](Fig4.Pacbio_overview.png){#Figure4-Overview}  

**Figure legend:** Construction of the multi-flux full-length transcriptome of *P. sibiricum*. (A) Length distribution of HiFi reads. (B) Quality distribution of HiFi reads. (C) BUSCO evaluation of the transcriptome completeness. (D) Annotation of the full-length nonredundant isoforms to multiple databases.
:::


## 3.1.2 Functional annotation

在所有非冗余的isoform中，143,998(81.19%)被至少一个数据库注释。其中至少被3个数据库注释到的isoform数量为108,732(61.55%)(Figure 4 D,Table S6)。注释到各个数据库的非冗余isoform数量如下：NR：140,472(97.56%), NT:113,682(78.95%), Swissprot:99,764(69.28%),KEGG:74,662(51.85%),KOG:62,479(43.39%)以及GO: 48,043(33.36%). 在注释覆盖度最全的NR注释中我们发现有86,970个isoform注释来源于*Asparagus officinalis*，占所有非冗余isoform的60.4%，而来源于其他物种的注释占比均不到5%（TableS7）,其中我们发现这些isoform匹配到13个黄精属（*Polygonatum*）注释,依次为：*Polygonatum verticillatum*（158），*Polygonatum sibiricum*（121），*Polygonatum cyrtonema* （53），*Polygonatum multiflorum*（46），*Polygonatum odoratum* （29），*Polygonatum pubescens * （12），*Polygonatum humile* （7）*Polygonatum sp. JJ-2020* （7），*Polygonatum zanlanscianense*（6），*Polygonatum kingianum*（4），*Polygonatum stenophyllum*（3），*Polygonatum cirrhifolium* （2），*Polygonatum roseum*（1）,序列同源性范围在37.99%-100%, 其中平均序列同源度较高的物种为*Polygonatum cirrhifolium* （99.6%），*Polygonatum verticillatum* （99.4%）,*Polygonatum stenophyllum* (99.3%),*Polygonatum sibiricum*(98.7%)等，较低的为*Polygonatum multiflorum*（69.0%），*Polygonatum roseum* （70.6%）以及*Polygonatum cyrtonema*（86.0%）TableS。

为了确定这些isoform可能影响的代谢通路，我们对KOG、KEGG、GO数据库的注释进行了分类。在KOG数据库中，我们发现62,479 isoforms 被分到4个大类中，4大类下又分了25个小类，其中注释到cellular processes and signaling大类的isoform有15,947个，而该大类中注释最多的类别为Signal transduction mechanisms和intracellular trafficking,secretion,and vesicular transport。注释到metabolism大类的isoform有10,589个，注释最多的两个term为Transcription以及Translation ribosomal structure and biogenesis.注释到Information storage and processing的有9,359个,其中Carbohydrate transport and metabolism和Energy production and conversion，Poorly Characterized以及无法分类的共有26,557个。共有48,043个isoform被注释到GO数据库中，其中biological process term注释到，其中KEGG共注释到74,622个isoform，根据KEGG层级结构这些注释被分配到5个最高层级(top hierarchy)：Cellular Processes(3,450), Environmental Information Processing(2,363), Genetic Information Processing(17,533), Metabolism(24,555),Organismal Systems(2,083), 而聚集最多的次层级(Second hierarchy)为Translation,有13.8%的isoform被注释到与蛋白质翻译(Translation)的pathway有关，接下来是KEGG term: Folding, sorting and degradation，占到总数的10.8% (Figure S3). 我们对这些高质量的全长转录本进行CDS预测，结果表明72.5% (128,026)的isoform可以预测到CDS序列,这些CDS序列的长度在主要集中在300-4000 nt之间(Figure S4 A),除此之外我们还预测了这些非冗余全长转录本的编码能力，最终我们发现有41.5% (73,175)的转录本符合长链非编码RNA（lncRNA）的特征，在这些candidate lncRNA中，有39,867的转录本中可能有CDS区域，占非冗余全长转录本的22.6%，而33,308的转录本不具有预测的CDS区域(Figure S4 B)。大部分的lncRNA范围在300-4000 nt (Figure S4 C). 除此之外，还有8.7%的全长转录本既无法预测到CDS区域，也不属于lncRNA，这些非冗余转录本被称为Transcript of Unknown Coding Potential (TUCP)@cabiliIntegrativeAnnotationHuman2011 (Figure S4 B).综上，这些数据证明在转录水平我们构建了丰富的，准确的转录本池（Transcript pool）为后续的黄精块茎的转录组研究。

# 4.讨论

## 4.1 我们通过三代全长转录组测序得到了高质量的黄精转录本信息。

由于缺乏参考基因组，通过转录组解析黄精块茎药用价值的研究只能通过无参转录组来进行，一部分研究基于Illumina平台的2代测序  @fengTranscriptomeAnalysisDifferent2022   @wangNovoAssemblyAnalysis2017，还有一些基于PacBio平台3代全长转录组测序 @liaoTranscriptomeProfilesRevealed2021 . 就测序质量而言，本研究subreads的N50达到了2164bp，高于二代测序的1532 bp  @wangNovoAssemblyAnalysis2017 1528 bp, @fengTranscriptomeAnalysisDifferent2022 略低于同样为三代测序的3166 bp   @liaoTranscriptomeProfilesRevealed2021 。本研究提供了高达176,643个非冗余序列，该数量要高于之前的黄精转录组鉴定的数量，@liaoTranscriptomeProfilesRevealed2021 鉴定到87,251个unigene, @wangNovoAssemblyAnalysis2017 鉴定到51,461个unigene，少于 @fengTranscriptomeAnalysisDifferent2022 鉴定到的575,977个。此外，就序列同源性注释而言，60%的非冗余基因注释到*Asparagus officinalis*的结论与之前的研究是一致的，但不同的是，@liaoTranscriptomeProfilesRevealed2021 等人的研究中与黄精属(*Polygonatum*)同源基因最多的是*P. cyrtonema* 和*P. multiflorum*，而本研究中最多的是*P. verticillatum*和*P. sibiricum*，接下来才是*P. cyrtonema* 和*P. multiflorum*。综上，我们从不同年份黄精块茎的三代全长转录组数据中获得了丰富的转录本，和前人的研究相比，测序质量较高，注释无明显偏倚，为后续黄精块茎转录组研究提供了高质量的转录本数据库。



# Figure preview

::: {#fig-batcheffect layout-nrow="1"}  

![Figure S3 Function annotation](FigS3.Annotation.png){#Figure1-Overview}  

:::  

::: {#fig-batcheffect layout-nrow="1"}  

![Figure S4 non-redundant length](FigS4.non_redundant.png){#Figure1-Overview}  

:::
  
# Table preview

<center>**Table S4. BUSCO non-redundant result.** 

```{r,echo=FALSE, message=FALSE, warning=FALSE,}
Tables4 <- import("../04.Result/01.Tables/TableS4.BUSCO1.xlsx",sheet = 1) %>% head() 
colnames(Tables4) = Tables4[1,]
Tables4 = Tables4[-1,]
print_table(Tables4,digits = 2)
```
</center>


<center>**Table S5. BUSCO all result.** 

```{r,echo=FALSE, message=FALSE, warning=FALSE,}
Tables5 <- import("../04.Result/01.Tables/TableS5.BUSCO2.xlsx",sheet = 1) %>% head()
colnames(Tables5) = Tables5[1,]
Tables5 = Tables5[-1,]
print_table(Tables5,digits = 2)
```
</center>
  
  
<center>**Table S6. Transcript annotation.** 

```{r,echo=FALSE, message=FALSE, warning=FALSE,}
Tables6 <- import("../04.Result/01.Tables/TableS6.Annotation_all.xlsx",sheet = 1) %>% head()
print_table(Tables6,digits = 2)
```
</center>

<center>**Table S7. Isoforms matched with Polygonatum species in NR database.** 

```{r,echo=FALSE, message=FALSE, warning=FALSE,}
Tables8 <- import("../04.Result/01.Tables/TableS7.Annotation_Summary.xlsx",sheet = 1) %>% head()
print_table(Tables8,digits = 2)
```
</center>
  
<center>**Table S8. Isoforms matched with Polygonatum species in NR database.** 

```{r,echo=FALSE, message=FALSE, warning=FALSE,}
Tables8 <- import("../04.Result/01.Tables/TableS8.xlsx",sheet = 1)
print_table(Tables8,digits = 2)
```
</center>


